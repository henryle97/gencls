
Common:
  use_gpu: true
  pretrained_model:                 # for train and infer
  resume_from:                      # only for train
  exp_dir: 'experiments/test'
  eval_during_training: true
  eval_per_epoch: 1
  epochs: 100
  print_per_step: 10

Metric: accuracy  # f1, confusion

Model:
  type: mobilenetv3
  hyperparameter:
    in_channels: 3
    # arch: small
    # scale: 0.35
    arch: large
    scale: 1
  num_classes: 2

Optimizer:
  name: Adam
  lr: 0.001

  betas: [0.9, 0.999]
  

Scheduler:
  name: OneCycleLR
  max_lr: 0.003
  pct_start: 0.3


Loss:
  name: CrossEntropyLoss

Dataset:
  # type: LMDBDataset
  # train_path:
  # test_path:
  type: SimpleDataset
  image_root: './DATA/hw_print_data_v1'
  train_label_path: './DATA/hw_print_data_v1/train_print_hw_cls.txt'
  val_label_path: './DATA/hw_print_data_v1/test_print_hw_cls.txt'
  
  Train:
    batch_size: 32
    transforms:
      - Resize:
          size: [48, 96]
          keep_ratio: true
      - ImgAugTransform:
      - Normalize: 
          scale: 1.0/255.0
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]   # rgb
    shuffle: true
  Eval:
    batch_size: 128
    transforms:
      - Resize:
          size: [48, 96]
          keep_ratio: true
      - Normalize: 
          scale: 1.0/255.0
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]   # rgb
    shuffle: false

DataLoader:
  num_workers: 4
  pin_memory: true

Infer:
  img: ./                 # dir or image path
  batch_size: 32
  transforms:
    - DecodeImage:
        to_rgb: true
    - Resize:
        size: [48, 96]
        keep_ratio: true
        
    - Normalize: 
        scale: 1.0/255.0
        # mean: [0.485, 0.456, 0.406]
        # std: [0.229, 0.224, 0.225]   # rgb
        mean: [0, 0, 0]
        std: [1, 1, 1]   # rgb

  shuffle: false
  PostProcess:
    name: Topk
    topk: 1
    class_id_mapping:
      print: 0
      handwriting: 1




